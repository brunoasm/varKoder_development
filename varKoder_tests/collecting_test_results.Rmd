---
title: "VarKoder testing"
output: html_notebook
---

To compare the performance of varKode to [Skmer](https://github.com/shahab-sarmashghi/Skmer), we will use leave-one-out cross validation: we remove one sample from the dataset, train a varKode model or make a skmer reference with the remaining samples, and then use the sample left out as query. We then record whether or not we correctly identify this sample in varKoder, and whether or not the closest sample with Skmer has the same identification. 

For traditional barcodes, we assembled the genome of each sample, and then used BLAST to search for each of the traditional barcode genes. We recorded if we could find this gene in the assembly, coding as missing data if we could not. We then recorded whether the best BLAST hit for a sample was the correct species.

```{r}
rm(list=ls())
library(tidyverse)
library(future)
library(ggthemes)
library(patchwork)
library(cowplot)
library(patchwork)
library(phytools)
library(ape)
library(furrr)
set.seed(14164)

#function to prevent overwriting plots
safe_ggsave <- function(filename, ...) {
  if (file.exists(filename)) {
    warning(paste("File", filename, "already exists. File not overwritten."))
    return(invisible(NULL))
  }
  ggsave(filename, ...)
}

```
# VarKoder
For VarKoder, we used leave-one-out cross-validation to test the accuracy for family, genera, species in the joint Malpighiaceae-Chrysobalanaceae dataset. We used as input data varKodes produced from kmers of size 7 and 500Kbp to 200Mbp of data, or all of the data available if less than 200 Mbp. For each sample, we built a model using as input data from all other samples. Then we queried the sample left out, using as input the images generated from 500Kb to the total data available. Now we will summarize the results.


## Accuracy vs data amount and taxonomic levels

In this test, we used varKoder [v0.8.0](https://github.com/brunoasm/varKoder/releases/tag/v.0.8.0). Let's process the results.

```{r}
read_and_process_xval = function(infolder){
  plan(multisession(workers = 12))
varkoder_results = list.files(infolder,
                                      'predictions.csv',
                                      recursive=T,
                                      full.names = T) %>%
  furrr::future_map_dfr(~read_csv(.x) %>% mutate(sample_id = as.character(sample_id))) %>% 
  select(-1) %>%
  mutate(query_basepairs = case_when(
    is.character(query_basepairs) ~ as.numeric(str_remove(query_basepairs, "K")) * 1000,
    TRUE ~ as.numeric(query_basepairs)
  )) %>%
  filter(str_detect(format(query_basepairs, scientific = FALSE,trim = TRUE), "^[125]0+$")) %>% #we will ignore queries that are not standardized sizes
  rename(query_bp = query_basepairs) %>%
  mutate(quality_included = T)
plan(sequential)

all_taxlabels = str_remove(varkoder_results$actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist %>% unique

varkoder_results = varkoder_results %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';'),
         predicted_list = str_split(predicted_labels,';')
         ) %>%
  rowwise() %>%
  mutate(family_correct = query_labels[str_detect(query_labels,'family')] %in% predicted_list,
         genus_correct = query_labels[str_detect(query_labels,'genus')] %in% predicted_list,
         species_correct = ifelse(any(str_detect(query_labels,'species')),
                                  query_labels[str_detect(query_labels,'species')] %in% predicted_list,
                                  NA
                                  ),
         family_incorrect = any(!(predicted_list[str_detect(predicted_list,'family')] %in% query_labels[str_detect(query_labels,'family')])),
         genus_incorrect = any(!(predicted_list[str_detect(predicted_list,'genus')] %in% query_labels[str_detect(query_labels,'genus')])),
         species_incorrect = ifelse(any(str_detect(query_labels,'species')),
                                  any(!(predicted_list[str_detect(predicted_list,'species')] %in% query_labels[str_detect(query_labels,'species')])),
                                  NA
                                  )
         
         )

return(varkoder_results)
}
```


```{r}
summarize_results = function(res,level){
  res = res %>%
    ungroup() %>%
    mutate(low_quality = str_detect(actual_labels,"low_quality:True"),
           result = as.character(ifelse(res[,str_c(level,'correct',sep='_')] & !res[,str_c(level,'incorrect',sep='_')], 'correct',
                           ifelse(res[,str_c(level,'correct',sep='_')] & res[,str_c(level,'incorrect',sep='_')], 'ambiguous',
                                  ifelse(!res[,str_c(level,'correct',sep='_')]  & res[,str_c(level,'incorrect',sep='_')], 'incorrect',
                                                 'inconclusive'
                                  ))))
           ) %>%
    filter(!is.na(result)) %>%
    group_by(query_bp,result) %>%
    summarise(N=n(), .groups = 'drop') %>%
    group_by(query_bp) %>%
    mutate(p= N/sum(N)) %>%
    #mutate(query_bp = as.integer(str_remove(query_bp,'K'))*1000) %>%
    ungroup() %>%
    mutate(query_bp = as.factor(query_bp)) %>%
    complete(query_bp,result, fill = list(p = 0, N = 0)) %>%
    mutate(query_bp = as.numeric(as.character(query_bp))) %>%
    ungroup()
    
  return(res)
}
```


```{r}
plot_area = function(sum_df, title, relative = FALSE, grid = TRUE, xlim_all = TRUE, wrap){
  breaks = c(500000,
             1000000,
             2000000,
             5000000,
             10000000,
             20000000,
             50000000,
             100000000,
             200000000
             )
  if (xlim_all){
    xlimits = range(breaks)
  } else {
    xlimits = range(sum_df$query_bp)
  }
  
  
  sum_df = sum_df %>%
    mutate(result = factor(result,ordered = T, levels = c('correct','ambiguous','inconclusive','incorrect'))) 
  if (relative){
    ylimits = c(0,1)
  } else {
    ylimits = c(0,sum_df %>% group_by(query_bp) %>% summarize(N=sum(N)) %>% pull(N) %>% max)
  }
  
  
  # Get colors from a Color Brewer palette
  brewer_colors <- RColorBrewer::brewer.pal(4, "Accent")
  
  if (relative) {
    p1 = ggplot(sum_df, aes(x=query_bp,y=p,fill=result)) +
    geom_area(position='stack') +
    scale_fill_manual(values = setNames(brewer_colors, c("correct", "ambiguous", "inconclusive", "incorrect"))) +
    scale_alpha_manual(values=c(0.5,1)) +
    scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = breaks)  +
    scale_y_continuous() +
    ggtitle(title) +
    ylab('Fraction of samples') +
    xlab('Base pairs in query images') +
    theme_few() +
    theme(axis.text.x = element_text(hjust=1,angle=45))
  } else {
      p1 = ggplot(sum_df, aes(x=query_bp,y=N,fill=result)) +
    geom_area(position='stack') +
    scale_fill_manual(values = setNames(brewer_colors, c("correct", "ambiguous", "inconclusive", "incorrect"))) +
    scale_alpha_manual(values=c(0.5,1)) +
    scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = breaks)   +
    scale_y_continuous() +
    ggtitle(title) +
    ylab('Number of samples') +
    xlab('Base pairs in query images') +
    theme_few() +
    theme(axis.text.x = element_text(hjust=1,angle=45))
  }
  
  if (grid){
    p1 = p1 +
      scale_y_continuous(n.breaks = 10, minor_breaks = waiver()) +
      theme(panel.background = element_rect(fill = NA),
            panel.grid.major.y = element_line(colour = gray(0.5)),
            panel.grid.minor.y = element_line(colour = gray(0.6),linetype = 2),
            panel.ontop = TRUE)
  }
  
  p1 = p1 + coord_cartesian(xlim=xlimits, ylim=ylimits,expand = FALSE)
  
  if (!missing(wrap)) {
    p1 = p1 + facet_wrap(as.formula(wrap))
  }
  
  return(p1)
}
  
```


Now let's plot genus-level accuracy:


```{r, message = FALSE, warning = FALSE}
results = read_and_process_xval('additional_tests_cgr/results_cgr_varKoder_vit_large_patch32_224/')
summary_genus = summarize_results(results,'genus')
p_genus = plot_area(summary_genus, 'varKoder genus', relative = TRUE)
p_genus
```
Now the same but with species
```{r}
summary_species = summarize_results(results,'species')
p_species = plot_area(summary_species, 'varKoder species', relative = TRUE)
p_species
```

Finally, family
```{r}
summary_family = summarize_results(results,'family')
p_family = plot_area(summary_family, 'varKoder family', relative = TRUE)
p_family
```
## what explains the errors?

Now we will try to identify which samples failed and why they failed. Particuarly, how do 
DNA quality, amount of data, and the number of samples per class impact results? We will use genus-level predictions to test.

```{r}
genus_predictions = results %>%
  mutate(predicted_genus = str_extract(predicted_labels, 'genus:[^;]*'),
         actual_genus = str_extract(actual_labels, 'genus:[^;]*')) %>%
  select(-starts_with('family'),-starts_with('species')) %>%
  pivot_longer(cols = starts_with("genus"), names_to = "predicted_label", values_to = "confidence") %>%
  filter(actual_genus == predicted_label) %>%
  select(query_bp, sample_id, basefrequency_sd, actual_genus, confidence) %>%
  mutate(query_bp = 1000*(str_remove(query_bp, "K") %>% as.integer))

genus_predictions = genus_predictions %>%
  select(sample_id, actual_genus) %>%
  distinct() %>%
  group_by(actual_genus) %>%
  summarise(N_samples = n()) %>%
  right_join(genus_predictions)

genus_predictions %>% arrange(N_samples)
```
Now let's make some plots. First, what is the effect of number of samples per class in confidence?
```{r}
set.seed(13214526)
plot_genus_N_vs_conf = ggplot(genus_predictions, aes(x = N_samples-1, 
                              y = confidence)) + 
  scale_color_viridis_c() +
  geom_jitter(alpha=0.3) + 
  scale_x_log10() +
  #ylab('Confidence in correct prediction\n(logit scale)') +
  ylab('Confidence in correct genus prediction') +
  xlab('Number of training samples in correct genus\n(log scale)') +
  #scale_y_continuous(trans = "logit", breaks = c(1e-4,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,0.999,1-1e-4)) +
  scale_y_continuous(limits=c(0,1)) +
  theme_few() +
  theme(panel.grid.major.y = element_line(colour = gray(0.8)))

plot_genus_N_vs_conf
```

Now, what is the effect of sample quality in confidence?
```{r}
set.seed(13214526)
plot_genus_freqsd_vs_conf = ggplot(genus_predictions, aes(x = basefrequency_sd, y = confidence)) + 
  geom_point(alpha=0.3) + 
  scale_x_log10() +
  #scale_y_continuous(trans = "logit", breaks = c(1e-4,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,0.999,1-1e-4)) +
  scale_y_continuous(limits=c(0,1)) +
  #ylab('Confidence in correct prediction\n(logit scale)') +
  ylab('Confidence in correct genus prediction') +
  xlab('Standard deviation of base frequencies') +
  theme_few() +
  theme(panel.grid.major.y = element_line(colour = gray(0.8)))

plot_genus_freqsd_vs_conf
```

Now, what is the effect of amount of data in confidence?
```{r}
set.seed(13214526)
plot_genus_bp_vs_conf = ggplot(genus_predictions, aes(x = query_bp, y = confidence)) + 
  geom_jitter(alpha=0.3) + 
  #scale_y_continuous(trans = "logit", breaks = c(1e-4,0.001,0.01,0.1,0.25,0.5,0.75,0.9,0.99,0.999,1-1e-4)) +
  scale_y_continuous(limits=c(0,1)) +
  #ylab('Confidence in correct prediction\n(logit scale)') +
  ylab('Confidence in correct genus prediction') +
  xlab('Base pairs in query images\n(log scale)') +
  scale_x_log10() +
  theme_few() +
  theme(panel.grid.major.y = element_line(colour = gray(0.8)))

plot_genus_bp_vs_conf
```

Let's put it all together now in a linear model. We remove one from N_samples since one sample is used for validation in the leave-one-out cross-validation that we did.

```{r}
lm_data = genus_predictions %>%
  mutate(confidence = ifelse(confidence == 1, confidence-0.0000001, confidence),
         confidence = car::logit(confidence)) %>%
  mutate(query_bp = (query_bp - mean(query_bp))/sd(query_bp),
         basefrequency_sd = (basefrequency_sd - mean(basefrequency_sd))/sd(basefrequency_sd),
         N_samples = ((N_samples-1) - mean(N_samples-1))/sd(N_samples-1)
         ) 

full_model = lm(formula = confidence~query_bp*basefrequency_sd*N_samples, data = lm_data) 
full_model
reduced_model = step(full_model,direction = 'both')
summary(reduced_model)
plot(reduced_model)

broom::tidy(reduced_model) %>% write_csv('lm_table.csv')
```

Now let's save the three of them as a single plot using cowplot.

```{r}
preds = genus_predictions %>%
  mutate(N_samples=N_samples-1) %>% 
  select(original_N = N_samples,
         original_bp = query_bp, 
         original_sd = basefrequency_sd) %>%
  mutate(query_bp = (original_bp - mean(original_bp))/sd(original_bp),
         basefrequency_sd = (original_sd - mean(original_sd))/sd(original_sd),
         N_samples = ((original_N) - mean(original_N))/sd(original_N)
         ) 

preds = bind_rows(expand.grid(query_bp=unique(preds$query_bp),
                              N_samples=0,
                              basefrequency_sd=0
                              ),
                  expand.grid(query_bp=0,
                              N_samples=unique(preds$N_samples),
                              basefrequency_sd=0
                              ),
                  expand.grid(query_bp=0,
                              N_samples=0,
                              basefrequency_sd=unique(preds$basefrequency_sd)
                              )
                  )

logistic <- function(L) {
  1 / (1 + exp(-L))
}

preds = predict(reduced_model, newdata=preds, interval='conf') %>%
  as_tibble() %>%
  mutate_all(~logistic(.x)+0.0000001) %>%
  rename(confidence=fit) %>%
  bind_cols(preds %>%
              mutate(N_samples = N_samples*sd(genus_predictions$N_samples-1)+mean(genus_predictions$N_samples-1),
                     basefrequency_sd = basefrequency_sd*sd(genus_predictions$basefrequency_sd)+
                       mean(genus_predictions$basefrequency_sd),
                     query_bp = query_bp*sd(genus_predictions$query_bp)+mean(genus_predictions$query_bp))
              )
  

```


```{r}
combined_conf = patchwork::wrap_plots(plot_genus_N_vs_conf + 
                                        theme(text = element_text(size=8)) + 
                                        geom_line(data=(filter(preds, 
                                                               N_samples != mean(genus_predictions$N_samples-1))),
                                                  color="blue") +
                                        geom_ribbon(data=(filter(preds, 
                                                               N_samples != mean(genus_predictions$N_samples-1))),
                                                    aes(ymin=lwr, ymax=upr), 
                                                        fill="lightblue", 
                                                        alpha=0.4),
                                      plot_genus_bp_vs_conf + theme(axis.title.y=element_blank(), 
                                                                    axis.text.y=element_blank(), 
                                                                    text = element_text(size=8)) +
                                        geom_line(data=(filter(preds, 
                                                               query_bp != mean(genus_predictions$query_bp))),
                                                  color="blue") +
                                        geom_ribbon(data=(filter(preds, 
                                                               query_bp != mean(genus_predictions$query_bp))),
                                                    aes(ymin=lwr, ymax=upr), 
                                                        fill="lightblue", 
                                                        alpha=0.4),
                                      plot_genus_freqsd_vs_conf + theme(axis.title.y=element_blank(), 
                                                                        axis.text.y=element_blank(),
                                                                        text = element_text(size=8)) +
                                        geom_line(data=(filter(preds, 
                                                               basefrequency_sd != mean(genus_predictions$basefrequency_sd))),
                                                  color="blue") +
                                        geom_ribbon(data=(filter(preds, 
                                                               basefrequency_sd != mean(genus_predictions$basefrequency_sd))),
                                                    aes(ymin=lwr, ymax=upr), 
                                                        fill="lightblue", 
                                                        alpha=0.4)) +
  patchwork::plot_annotation(tag_levels = 'A',
                             title = 'Factors affecting varKode prediction accuracy',theme = theme(plot.title = element_text(hjust=0.5))) 

combined_conf

safe_ggsave (filename = 'images_manuscript/supp_conf_predictors.pdf',device = 'pdf',width = 7,height=3,units = 'in',useDingbats=F)
```

## Skmer

For skmer, we left each sample out, built a reference and then queried that sample. We have several files in which reference samples are ordered by their distance to the query, we here we will evaluate whether the closest sample is from the correct species or genus.

Because it is not clear how skmer behaves for different levels of coverage, we repeated this for several input sizes (in number of basepairs) as query, but always used the maximum input dize available (up to 200Mb) for references.

Let's make a function that extracts these results as a table.

```{r}

samp_labels = results %>% select(sample_id,actual_labels) %>% distinct()

extract_skmer_results = function(file_path) {
    # Read only the first 2 lines of the file
    file_lines <- readLines(file_path, n = 2)
    
    # Extract sample_ID, basepairs from the first line
    sample_info <- str_match(file_lines[1], "\\s*(.*?)@(\\d+K)")[, 2:3]
    sample_ID <- sample_info[1]
    basepairs <- sample_info[2]
    
    # Extract reference_sample_ID, distance from the second line
    reference_info <- str_match(file_lines[2], "\\s*(.*?)@.*\\s+(\\d+\\.\\d+)")[, 2:3]
    reference_sample_ID <- reference_info[1]
    distance <- as.numeric(reference_info[2])
    
    # Create a tibble
    tibble(
        sample_id = sample_ID,
        query_bp = basepairs,
        closest_reference_sample_id = reference_sample_ID,
        closest_distance = distance
    ) 
}
```

Now we will apply this function to all skmer output files.

```{r}
plan(multisession(workers = 12))
skmer_results_df = furrr::future_map_dfr(
  list.files('Malpighiales/skmer/skmer_xval_results/', full.names = T),
  ~ extract_skmer_results(.x)
) %>%
  left_join(samp_labels, by = 'sample_id') %>%
  left_join(
    samp_labels %>% select(
      closest_reference_sample_id = 'sample_id',
      predicted_labels = actual_labels
    ),
    by = 'closest_reference_sample_id'
  ) %>%
  mutate(
    query_labels = str_remove(actual_labels, ";*low_quality:True;*") %>% str_split(';'),
    predicted_list = str_split(predicted_labels, ';')
  ) %>%
  rowwise() %>%
  mutate(
    family_correct = query_labels[str_detect(query_labels, 'family')] %in% predicted_list,
    genus_correct = query_labels[str_detect(query_labels, 'genus')] %in% predicted_list,
    species_correct = ifelse(any(str_detect(
      query_labels, 'species'
    )),
    query_labels[str_detect(query_labels, 'species')] %in% predicted_list,
    NA),
    family_incorrect = any(!(predicted_list[str_detect(predicted_list, 'family')] %in% query_labels[str_detect(query_labels, 'family')])),
    genus_incorrect = any(!(predicted_list[str_detect(predicted_list, 'genus')] %in% query_labels[str_detect(query_labels, 'genus')])),
    species_incorrect = ifelse(any(str_detect(
      query_labels, 'species'
    )),
    any(!(
      predicted_list[str_detect(predicted_list, 'species')] %in% query_labels[str_detect(query_labels, 'species')]
    )),
    NA),
    query_bp = as.numeric(str_remove(query_bp, "K")) * 1000
    
  ) 
plan(sequential)
skmer_results_df
```
Now let's summarize and plot by genus:

```{r}
skmer_summary_genus = summarize_results(skmer_results_df,'genus')
p_skmer_genus = plot_area(skmer_summary_genus, 'Skmer genus', relative = TRUE)
p_skmer_genus
```
Now by species. In Skmer, there is no inconclusive result: if there is no correct species prediction, it means that a sample was predicted in the wrong genus and therefore it is incorrect

```{r}
skmer_summary_species = summarize_results(skmer_results_df,'species') %>%
  mutate(result = ifelse(result == 'correct', 'correct','incorrect')) %>%
  group_by(query_bp,result) %>%
  summarise_all(sum)
p_skmer_species = plot_area(skmer_summary_species, 'Skmer species', relative = TRUE)
p_skmer_species
```

And now by family:

```{r}
skmer_summary_family = summarize_results(skmer_results_df,'family')
skmer_summary_family 
p_skmer_family = plot_area(skmer_summary_family, 'Skmer family', relative = TRUE)
p_skmer_family
```

# Traditional barcodes
## BLAST single gene
Let's now read the traditional barcode BLAST results and summarize them in the same way as skmer and varKoder. Let's start by defining a fuction that reads the data so we can summarize it using the previously defined functions.

```{r}
read_traditional_barcodes = function(bp) {
  input_file = paste0(
    'Malpighiales/traditional_barcodes/2_blast_phylogeny_result/Genus/',
    bp,
    'M_blast_phylo_sum_sp.tsv'
  )
  
  barcode_res = read_delim(input_file) %>%
    pivot_longer(-sp, names_to = 'marker', values_to = 'closest_reference_sample_id') %>%
    rename(sample_id = 'sp') %>%
    mutate(
      sample_id = str_remove_all(sample_id, '@.+'),
      closest_reference_sample_id = str_remove_all(closest_reference_sample_id, '@.+'),
      predicted_labels = samp_labels$actual_labels[match(closest_reference_sample_id, samp_labels$sample_id)],
      actual_labels = samp_labels$actual_labels[match(sample_id, samp_labels$sample_id)]
    ) %>%
    filter(marker != 'Concatenated_phylogeny') %>%
    mutate(
      query_labels = str_remove(actual_labels, ";*low_quality:True;*") %>% str_split(';'),
      predicted_list = str_split(predicted_labels, ';')
    ) %>%
    rowwise() %>%
    mutate(
      family_correct = query_labels[str_detect(query_labels, 'family')] %in% predicted_list,
      genus_correct = query_labels[str_detect(query_labels, 'genus')] %in% predicted_list,
      species_correct = ifelse(any(str_detect(
        query_labels, 'species'
      )),
      query_labels[str_detect(query_labels, 'species')] %in% predicted_list,
      NA),
      family_incorrect = any(!(predicted_list[str_detect(predicted_list, 'family')] %in% query_labels[str_detect(query_labels, 'family')])),
      genus_incorrect = any(!(predicted_list[str_detect(predicted_list, 'genus')] %in% query_labels[str_detect(query_labels, 'genus')])),
      species_incorrect = ifelse(any(str_detect(
        query_labels, 'species'
      )),
      any(!(
        predicted_list[str_detect(predicted_list, 'species')] %in% query_labels[str_detect(query_labels, 'species')]
      )),
      NA)
    ) %>%
    mutate_at(vars(ends_with("_correct"), ends_with("_incorrect")),
              ~ ifelse(is.na(predicted_labels) & !is.na(.), FALSE, .)) %>%
    mutate(query_bp = bp * 1e6)
  
  return(barcode_res)
}
```


Now we can apply this function to all of our results:

```{r}
results_barcodes = purrr::map_dfr(c(0.5,1,2,5,10,20,50,100,200),read_traditional_barcodes)
results_barcodes
```

Now let's summarise for each marker separately:
```{r}
barcode_summary_family = split(results_barcodes,results_barcodes$marker) %>%
  purrr::map_dfr(~summarize_results(.x,'family'),.id='marker')

barcode_summary_family
```

```{r}
barcode_summary_genus = split(results_barcodes,results_barcodes$marker) %>%
  purrr::map_dfr(~summarize_results(.x,'genus'),.id='marker')

barcode_summary_genus
```

```{r}
barcode_summary_species = split(results_barcodes,results_barcodes$marker) %>%
  purrr::map_dfr(~summarize_results(.x,'species'),.id='marker')

barcode_summary_species
```

Now let's plot, making separate plots for each marker:

Species:
```{r}
p_barcode_species = barcode_summary_species %>%
  split(barcode_summary_species$marker) %>%
  purrr::map(~plot_area(.x,paste0(unique(.x$marker),' species'), relative = TRUE, xlim_all = TRUE))

p_barcode_species
```
Genera:
```{r}
p_barcode_genus = barcode_summary_genus %>%
  split(barcode_summary_genus$marker) %>%
  purrr::map(~plot_area(.x,paste0(unique(.x$marker),' genus'), relative = TRUE, xlim_all = TRUE))

p_barcode_genus
```
Family:
```{r}
p_barcode_family = barcode_summary_family %>%
  split(barcode_summary_family$marker) %>%
  purrr::map(~plot_area(.x,paste0(unique(.x$marker),' family'), relative = TRUE,xlim_all = TRUE))

p_barcode_family
```

## Concatenated tree
Now we will do the same for concatenated tree. Let's start by defining a function to gather results. We will consider a result as correct if the majority of the sister taxon to a tip has the same label.


```{r}

read_concatenated_tree_results = function(bp){
  
  
# Read in your tree - replace 'your_tree_file.nwk' with the path to your tree file
tree = read.tree(paste0('Malpighiales/traditional_barcodes/2_blast_phylogeny_result/Genus/conc.',bp,'m.spname.tre'))

#leave only sample IDs as tip labels
tree$tip.label = tree$tip.label %>% str_remove(".*@") %>% str_remove("'") %>% str_replace(' ref','_ref')

# Compute the patristic distances and list all reference names
patristic_distances <- cophenetic(tree)
all_ref_names = dimnames(patristic_distances)[[1]][str_detect(dimnames(patristic_distances)[[1]],'_ref$')]
all_nonref = dimnames(patristic_distances)[[1]][str_detect(dimnames(patristic_distances)[[1]],'_ref$',negate = TRUE)]

# For each tip, find the reference sample with closest patristic distance
find_closest = function(tip){
  to_keep = c(tip,all_ref_names[str_detect(all_ref_names,paste0(tip,'_ref'),negate = TRUE)])
  return(names(sort(patristic_distances[tip,to_keep])[2]) %>%
           str_remove('_ref'))
}

closest_match = purrr::map_chr(all_nonref,find_closest)

samples_with_data = read_delim(paste0('Malpighiales/traditional_barcodes/2_blast_phylogeny_result/Genus/',bp,'M_blast_phylo_sum_sp.tsv')) %>% 
  select(sample_id=sp) %>%
  mutate(sample_id = str_remove_all(sample_id, '@.+'))

barcode_res = tibble(sample_id = all_nonref,
       closest_reference_sample_id = closest_match) %>%
  right_join(samples_with_data) %>%
  mutate(
      predicted_labels = samp_labels$actual_labels[match(closest_reference_sample_id, samp_labels$sample_id)],
      actual_labels = samp_labels$actual_labels[match(sample_id, samp_labels$sample_id)]
    ) %>%
  filter(sample_id!='2095') %>%
  mutate(
      query_labels = str_remove(actual_labels, ";*low_quality:True;*") %>% str_split(';'),
      predicted_list = str_split(predicted_labels, ';')
    ) %>%
    rowwise() %>%
    mutate(
      family_correct = query_labels[str_detect(query_labels, 'family')] %in% predicted_list,
      genus_correct = query_labels[str_detect(query_labels, 'genus')] %in% predicted_list,
      species_correct = ifelse(any(str_detect(
        query_labels, 'species'
      )),
      query_labels[str_detect(query_labels, 'species')] %in% predicted_list,
      NA),
      family_incorrect = any(!(predicted_list[str_detect(predicted_list, 'family')] %in% query_labels[str_detect(query_labels, 'family')])),
      genus_incorrect = any(!(predicted_list[str_detect(predicted_list, 'genus')] %in% query_labels[str_detect(query_labels, 'genus')])),
      species_incorrect = ifelse(any(str_detect(
        query_labels, 'species'
      )),
      any(!(
        predicted_list[str_detect(predicted_list, 'species')] %in% query_labels[str_detect(query_labels, 'species')]
      )),
      NA)
    ) %>%
    mutate_at(vars(ends_with("_correct"), ends_with("_incorrect")),
              ~ ifelse(is.na(predicted_labels) & !is.na(.), FALSE, .)) %>%
    mutate(query_bp = bp * 1e6)
  
  return(barcode_res)
}

```

Now let's apply this function
```{r}
results_concat_barcodes = purrr::map_dfr(c(0.5,1,2,5,10,20,50,100,200),read_concatenated_tree_results)
results_concat_barcodes
```
Let's summarize results and plot for genus, species and family accuracy

```{r}
concat_summary_species = summarize_results(results_concat_barcodes,'species')
p_concat_species = plot_area(concat_summary_species, relative = FALSE,title = 'Concatenated barcodes species',xlim_all = TRUE)
p_concat_species
```
```{r}
concat_summary_genus = summarize_results(results_concat_barcodes,'genus')
p_concat_genus = plot_area(concat_summary_genus, relative = TRUE,title = 'Concatenated barcodes genus',xlim_all = TRUE)
p_concat_genus
```

```{r}
concat_summary_family = summarize_results(results_concat_barcodes,'family')
p_concat_family = plot_area(concat_summary_family, relative = TRUE,title = 'Concatenated barcodes family',xlim_all = TRUE)
p_concat_family
```


# Direct comparison

Now let's compare methods side by side. For genus level:
```{r fig.height=10}
p = patchwork::wrap_plots(p_genus + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()), 
                   p_skmer_genus + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_barcode_genus$ITS + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_barcode_genus$rbcL + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_concat_genus,
                   ncol = 1) +
  plot_annotation(title = 'Genus-level accuracy')
p
safe_ggsave ('images_manuscript/fig3_genus_accuracy.pdf', width=5,height = 10)
safe_ggsave ('images_manuscript/fig3_genus_accuracy.png', width=5,height = 10,dpi=1200)
```
Now for species level:
```{r fig.height = 10}
p = patchwork::wrap_plots(p_species + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()), 
                   p_skmer_species + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_barcode_species$ITS + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_barcode_species$rbcL + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_concat_species,
                   ncol = 1) +
  plot_annotation(title = 'species-level accuracy')
p
safe_ggsave ('images_manuscript/fig3_species_accuracy.pdf', width=5,height = 10)
safe_ggsave ('images_manuscript/fig3_species_accuracy.png', width=5,height = 10,dpi=1200)
```
Now for family level:
```{r fig.height = 10}
p = patchwork::wrap_plots(p_family + ggtitle('varKoder') + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank(),
                                           legend.position = 'none'), 
                   p_skmer_family + ggtitle('Skmer') + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank(),
                                          legend.position = 'none'),
                   p_barcode_family$ITS + ggtitle('ITS') + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank()),
                   p_barcode_family$rbcL + ggtitle('rbcL') + theme(axis.text.x = element_blank(),
                                           axis.title.x = element_blank(),
                                           legend.position = 'none'),
                   p_concat_family + ggtitle('Concatenated conventional barcodes') + theme(legend.position = 'none'),
                   ncol = 1,guides = 'collect') +
  plot_annotation(title = 'Family-level accuracy',theme = theme(plot.title=element_text(hjust=0.5)))
p
safe_ggsave ('images_manuscript/fig3_family_accuracy.pdf', width=5,height = 10)
safe_ggsave ('images_manuscript/fig3_family_accuracy.png', width=5,height = 10,dpi=1200)
```

Now let's plot a figure for the other traditional barcode loci that did not make this list.

```{r}
p1 = patchwork::wrap_plots(ggplot() + 
                             theme_minimal() + 
                             ggtitle("Species") + 
                             theme(plot.title = element_text(hjust=0.5),
                                   plot.margin = unit(c(0,0,0,0),'lines')),
                           p_barcode_species$matK + 
                             ggtitle('matK') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_species$ndhF +
                             ggtitle('ndhF') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_species$`trnL-F` +
                             ggtitle('trnL-F') +
                             theme(axis.title.y =element_blank(),
                                   legend.position = 'none',
                                   axis.title.x =element_blank()),
                   ncol = 1,
                  heights = c(1,15,15,15)
                  ) 


p2 = patchwork::wrap_plots(ggplot() + 
                             theme_minimal() + 
                             ggtitle("Genus") + 
                             theme(plot.title = element_text(hjust=0.5),
                                   plot.margin = unit(c(0,0,0,0),'lines')),
                           p_barcode_genus$matK + 
                             ggtitle('matK') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_genus$ndhF +
                             ggtitle('ndhF') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_genus$`trnL-F` +
                             ggtitle('trnL-F') +
                             theme(axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                   legend.position = 'none',
                                   axis.title.x =element_blank()),
                   ncol = 1,
                  heights = c(1,15,15,15)) 

p3 = patchwork::wrap_plots(ggplot() + 
                             theme_minimal() + 
                             ggtitle("Family") + 
                             theme(plot.title = element_text(hjust=0.5),
                                   plot.margin = unit(c(0,0,0,0),'lines')),
                           p_barcode_family$matK + 
                             ggtitle('matK') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_family$ndhF +
                             ggtitle('ndhF') +
                              theme(axis.text.x = element_blank(),
                                    axis.title.x = element_blank(),
                                    axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                    legend.position = 'none'),
                           p_barcode_family$`trnL-F` +
                             ggtitle('trnL-F') +
                             theme(axis.title.y =element_blank(),
                                    axis.text.y =element_blank(),
                                   axis.title.x =element_blank()),
                   ncol = 1,
                   heights = c(1,15,15,15),
                   guides='collect')

p = patchwork::wrap_plots(p1,p2,p3,ncol=3,guides="collect") +
   plot_annotation(
    title = 'Conventional barcode accuracy across different taxonomic levels',
    theme = theme(plot.title = element_text(hjust = 0.2,face='bold',size=15))
  )

safe_ggsave ('images_manuscript/supp_traditional_barcodes.pdf', plot = p, width=8,height = 6)
```



# SRA: eukaryotic families

## varKodes

Finally, let's summarize results for the whole SRA dataset. In this case, we only have varKoder since Skmer cannot finish and traditional barcodes are inapplicable. We have done predictions separately for families included in the training set and families not included in the trainings set, so we will load each one and concatenate

```{r}
varKoder_SRA_results  = read_csv('all_SRA_eukaryote_families/vkfCGR_query_results/predictions.csv') %>%
select(-1) %>%
  mutate(query_basepairs = case_when(
    is.character(query_basepairs) ~ as.numeric(str_remove(query_basepairs, "K")) * 1000,
    TRUE ~ as.numeric(query_basepairs)
  )) %>%
  filter(str_detect(format(query_basepairs, scientific = FALSE,trim = TRUE), "^[125]0+$")) %>% #we will ignore queries that are not standardized sizes
  rename(query_bp = query_basepairs) %>%
  mutate(quality_included = T)
plan(sequential)


varKoder_SRA_results = varKoder_SRA_results %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist,
         predicted_list = str_split(predicted_labels,';')
         ) %>%
  rowwise() %>%
  mutate(family_correct = query_labels %in% predicted_list,
         family_incorrect = ifelse(is.na(predicted_labels),FALSE,any(!(predicted_list %in% query_labels))),
         family_in_training = TRUE) %>%
 select(matches("^[^0-9]"))

varKoder_SRA_results 
         
```

```{r}
varKoder_SRA_results_notincluded  = read_csv('all_SRA_eukaryote_families/vkfCGR_query_notincluded_results/predictions.csv') %>%
select(-1) %>%
  mutate(query_basepairs = case_when(
    is.character(query_basepairs) ~ as.numeric(str_remove(query_basepairs, "K")) * 1000,
    TRUE ~ as.numeric(query_basepairs)
  )) %>%
  filter(str_detect(format(query_basepairs, scientific = FALSE,trim = TRUE), "^[125]0+$")) %>% #we will ignore queries that are not standardized sizes
  rename(query_bp = query_basepairs) %>%
  mutate(quality_included = T)
plan(sequential)

SRA_taxlabels_notincluded = str_remove(varKoder_SRA_results_notincluded$actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist %>% unique

varKoder_SRA_results_notincluded = varKoder_SRA_results_notincluded %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist,
         predicted_list = str_split(predicted_labels,';')
         ) %>%
  rowwise() %>%
  mutate(family_correct = query_labels %in% predicted_list,
         family_incorrect = ifelse(is.na(predicted_labels),FALSE,any(!(predicted_list %in% query_labels))),
         family_in_training = FALSE) %>%
 select(matches("^[^0-9]"))

varKoder_SRA_results_notincluded 
```

Now let's summarize and plot:

```{r}
SRA_summary_family = bind_rows(summarize_results(varKoder_SRA_results,'family') %>% mutate(family_in_training = TRUE),
                               summarize_results(varKoder_SRA_results_notincluded,'family') %>% mutate(family_in_training = FALSE))
SRA_summary_family

N_samp = SRA_summary_family %>%
 group_by(query_bp, family_in_training) %>%
 summarise(N = sum(N))

p_SRA_family = plot_area(SRA_summary_family, 'varKoder SRA family', relative = TRUE,xlim_all = FALSE, wrap = '~family_in_training')
p_SRA_family 
```

Let's now do the SRA plot, but splitting by kingdom and whether or not family was included in training. First, we need to retrieve kingdom information:
```{r}

summary_SRA_by_kingdom = read_csv('all_SRA_eukaryote_families/runs_to_download_data.csv') %>%
  select(sample_id = Run, Kingdom) %>%
  right_join(varKoder_SRA_results) %>%
  split(.$Kingdom) %>%
  purrr::map_df(summarize_results, 
                 level='family',
                .id='Kingdom'
                ) %>%
  mutate(Kingdom = factor(Kingdom,levels=c('Metazoa','Viridiplantae','Fungi'),ordered = T),
         family_in_training = T) %>%
  bind_rows(read_csv('all_SRA_eukaryote_families/runs_notincluded_to_download_data.csv') %>%
  select(sample_id = Run, Kingdom) %>%
  right_join(varKoder_SRA_results_notincluded) %>%
  split(.$Kingdom) %>%
  purrr::map_df(summarize_results, 
                 level='family',
                .id='Kingdom'
                ) %>%
  mutate(Kingdom = factor(Kingdom,levels=c('Metazoa','Viridiplantae','Fungi'),ordered = T),
         family_in_training = F)) %>%
  mutate(family_in_training = c('Family\nnot in training set', 'Family\nin training set')[family_in_training+1])
summary_SRA_by_kingdom 


p_SRA_families = plot_area(summary_SRA_by_kingdom ,
          relative=FALSE,
          xlim_all = FALSE,
          title='Eukaryote families') + 
  facet_grid(family_in_training~Kingdom) +
  coord_cartesian(xlim=c(500,10000)*1000,expand = FALSE) +
  theme(text = element_text(size=10))

print(p_SRA_families)


safe_ggsave ('images_manuscript/fig3_SRA_accuracy.pdf', width=5,height = 4)
safe_ggsave ('images_manuscript/fig3_SRA_accuracy.png', width=5,height = 4,dpi = 1200)
```
## VarKodes
We repeated this analysis with varKodes. Let's compare now.
```{r}
plan(sequential)

varKoder_SRA_results_vk = read_csv('all_SRA_eukaryote_families/varkoder_query_results/predictions.csv',
                                    col_types = list(query_basepairs = "c")) %>%
  select(-1) %>%
  filter(str_detect(query_basepairs,'^0*[125]0+K$')) %>%
  mutate(query_bp = as.numeric(str_remove(query_basepairs,'K'))*1000)

varKoder_SRA_results_vk = varKoder_SRA_results_vk %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist,
         predicted_list = str_split(predicted_labels,';')
  ) %>%
  rowwise() %>%
  mutate(family_correct = query_labels %in% predicted_list,
         family_incorrect = ifelse(is.na(predicted_labels),FALSE,any(!(predicted_list %in% query_labels))),
         family_in_training = TRUE) %>%
  select(matches("^[^0-9]")) 
  

varKoder_SRA_results_notincluded_vk = read_csv('all_SRA_eukaryote_families/varkoder_query_notincluded_results/predictions.csv',
                                                col_types = list(query_basepairs = "c")) %>%
  select(-1) %>%
  filter(str_detect(query_basepairs,'^0*[125]0+K$')) %>%
  mutate(query_bp = as.numeric(str_remove(query_basepairs,'K'))*1000)

SRA_taxlabels_notincluded_vk = str_remove(varKoder_SRA_results_vk$actual_labels,";*low_quality:True;*") %>% 
  str_split(';') %>% 
  unlist %>% 
  unique 

varKoder_SRA_results_notincluded_vk = varKoder_SRA_results_notincluded_vk %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist,
         predicted_list = str_split(predicted_labels,';')
  ) %>%
  rowwise() %>%
  mutate(family_correct = query_labels %in% predicted_list,
         family_incorrect = ifelse(is.na(predicted_labels),FALSE,any(!(predicted_list %in% query_labels))),
         family_in_training = FALSE) %>%
  select(matches("^[^0-9]"))

# Summary statistics
SRA_summary_family_vk = bind_rows(
  summarize_results(varKoder_SRA_results_vk,'family') %>% mutate(family_in_training = TRUE),
  summarize_results(varKoder_SRA_results_notincluded_vk,'family') %>% mutate(family_in_training = FALSE)
)

N_samp_vk = SRA_summary_family_vk %>%
  group_by(query_bp, family_in_training) %>%
  summarise(N = sum(N))

# Kingdom summary
summary_SRA_by_kingdom_vk = read_csv('all_SRA_eukaryote_families/runs_to_download_data.csv') %>%
  select(sample_id = Run, Kingdom) %>%
  right_join(varKoder_SRA_results_vk) %>%
  split(.$Kingdom) %>%
  purrr::map_df(summarize_results, 
                level='family',
                .id='Kingdom') %>%
  mutate(Kingdom = factor(Kingdom,levels=c('Metazoa','Viridiplantae','Fungi'),ordered = TRUE),
         family_in_training = TRUE) %>%
  bind_rows(
    read_csv('all_SRA_eukaryote_families/runs_notincluded_to_download_data.csv') %>%
      select(sample_id = Run, Kingdom) %>%
      right_join(varKoder_SRA_results_notincluded_vk) %>%
      split(.$Kingdom) %>%
      purrr::map_df(summarize_results, 
                    level='family',
                    .id='Kingdom') %>%
      mutate(Kingdom = factor(Kingdom,levels=c('Metazoa','Viridiplantae','Fungi'),ordered = TRUE),
             family_in_training = FALSE)
  ) %>%
  mutate(family_in_training = c('Family\nnot in training set', 'Family\nin training set')[family_in_training+1])

# Final plot
p_SRA_families_vk = plot_area(summary_SRA_by_kingdom_vk,
                          relative=FALSE,
                          xlim_all = FALSE,
                          title='Eukaryote families') + 
  facet_grid(family_in_training~Kingdom) +
  coord_cartesian(xlim=c(500,10000)*1000,expand = FALSE) +
  theme(text = element_text(size=10))

p_SRA_families_vk

```

The graph looks almost identical, let's make a table comparing side-by-side. It seems rfCGRs are slightly better.

```{r}
full_join(
select(summary_SRA_by_kingdom_vk,Kingdom,query_bp,result,p,family_in_training),
select(summary_SRA_by_kingdom,,Kingdom,query_bp,result,p,family_in_training),
by=join_by(Kingdom,query_bp,result,family_in_training),
suffix = c('.varKode','.rfCGR')
) %>%
  mutate(difference = p.varKode-`p.rfCGR`) %>%
  arrange(family_in_training,result,query_bp,Kingdom)
```



# Other species-level datasets

## varKodes

Now we will make a small figure to include the additional datasets in which we applied varKoding.

In these cases, we chose a test set that included both taxa in the training set and taxa not in the training set, so we will graph both separately. This is denoted by a column named `in_training_model`. Let's start by reading results.

Let's define a function to read and process predictions:

```{r}
read_and_process_others = function(infile){
  
varkoder_results = read_csv(infile) %>% 
  mutate(sample_id = as.character(sample_id)) %>%
  select(-1) %>%
  rename(query_bp = query_basepairs) 


all_taxlabels = str_remove(varkoder_results$actual_labels,";*low_quality:True;*") %>% str_split(';') %>% unlist %>% unique

varkoder_results = varkoder_results %>%
  mutate(query_labels = str_remove(actual_labels,";*low_quality:True;*") %>% str_split(';'),
         predicted_list = str_split(predicted_labels,';')
         ) %>%
  rowwise() %>%
  mutate(taxon_correct = any(query_labels %in% predicted_list),
         taxon_incorrect = any(!(predicted_list[!is.na(predicted_list)] %in% query_labels))
         )

return(varkoder_results)
}
```

Now let's apply this function to all files.
```{r}
prediction_files = list.files('other_datasets/varKode/',pattern = 'predictions.+csv',full.names = T,recursive = T)
names(prediction_files) = basename(prediction_files) %>% str_extract(".*(?=_predictions\\.csv)")

other_results = purrr::map_dfr(prediction_files, read_and_process_others, .id='dataset')
other_results
```

Let's now summarize by dataset and separately for taxa included and excluded from the training set.

```{r}
summary_others = other_results %>%
  split(interaction(other_results$dataset, other_results$in_training_model)) %>%
  purrr::map_dfr(summarize_results, level = 'taxon', .id = 'comb') %>%
  separate(comb, into = c("dataset", "taxon_in_training_raw"), sep = "\\.") %>%
  mutate(taxon_in_training = taxon_in_training_raw == 'yes') %>%
  select(-taxon_in_training_raw) %>%
  mutate(taxon_in_training = c('Taxon not in training set', 'Taxon in training set')[taxon_in_training+1],
         dataset = str_replace(dataset, "^(.)", ~toupper(.x))) %>%
  mutate(result = factor(result,
                         levels=c("correct", "ambiguous", "inconclusive", "incorrect"),
                         ordered=T))

summary_others

```
Now let's plot
```{r}
p_others = ggplot(summary_others , aes(x = dataset, y = N, fill = result)) +
  geom_col()+
    scale_fill_manual(values = setNames(RColorBrewer::brewer.pal(4, "Accent"), c("correct", "ambiguous", "inconclusive", "incorrect"))) +
    scale_alpha_manual(values=c(0.5,1)) +
    ggtitle('Other datasets') +
    ylab('Number of samples') +
    xlab('Taxon') +
    theme_few() +
      scale_y_continuous(minor_breaks = waiver()) +
      theme(panel.background = element_rect(fill = NA),
            panel.grid.major.y = element_line(colour = gray(0.5)),
            panel.grid.minor.y = element_line(colour = gray(0.6),linetype = 2),
            axis.title.x = element_blank(),
            axis.text.x = element_text(face='italic'),
            panel.ontop = TRUE) +
    coord_cartesian(expand=FALSE) +
    facet_grid(taxon_in_training~.) +
    theme(text = element_text(size=10),
          axis.text.x = element_text(angle = 30,hjust = 1))
  
p_others

```

## CGR
Let's repeat everything for CGR representation now
```{r}
# Read prediction files
prediction_files_CGR = list.files('other_datasets/cgr/',pattern = 'predictions.+csv',full.names = TRUE,recursive = T)
names(prediction_files_CGR) = basename(prediction_files_CGR) %>% str_extract(".*(?=_predictions\\.csv)")
other_results_CGR = purrr::map_dfr(prediction_files_CGR, read_and_process_others, .id='dataset')

# Create summary
summary_others_CGR = other_results_CGR %>%
  split(interaction(other_results_CGR$dataset, other_results_CGR$in_training_model)) %>%
  purrr::map_dfr(summarize_results, level = 'taxon', .id = 'comb') %>%
  separate(comb, into = c("dataset", "taxon_in_training_raw"), sep = "\\.") %>%
  mutate(taxon_in_training = taxon_in_training_raw == 'yes') %>%
  select(-taxon_in_training_raw) %>%
  mutate(taxon_in_training = c('Taxon not in training set', 'Taxon in training set')[taxon_in_training+1],
         dataset = str_replace(dataset, "^(.)", ~toupper(.x))) %>%
  mutate(result = factor(result,
                        levels=c("correct", "ambiguous", "inconclusive", "incorrect"),
                        ordered=TRUE))

# Create plot
p_others_CGR = ggplot(summary_others_CGR, aes(x = dataset, y = N, fill = result)) +
  geom_col() +
  scale_fill_manual(values = setNames(RColorBrewer::brewer.pal(4, "Accent"), 
                                    c("correct", "ambiguous", "inconclusive", "incorrect"))) +
  scale_alpha_manual(values=c(0.5,1)) +
  ggtitle('Other datasets') +
  ylab('Number of samples') +
  xlab('Taxon') +
  theme_few() +
  scale_y_continuous(minor_breaks = waiver()) +
  theme(panel.background = element_rect(fill = NA),
        panel.grid.major.y = element_line(colour = gray(0.5)),
        panel.grid.minor.y = element_line(colour = gray(0.6),linetype = 2),
        axis.title.x = element_blank(),
        axis.text.x = element_text(face='italic'),
        panel.ontop = TRUE) +
  coord_cartesian(expand=FALSE) +
  facet_grid(taxon_in_training~.) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle = 30,hjust = 1))

p_others_CGR

safe_ggsave ('images_manuscript/fig3_others_accuracy.pdf', width=3.5,height = 3)
safe_ggsave ('images_manuscript/fig3_others_accuracy.png', width=3.5,height = 3,dpi = 1200)
```

# SRA: all taxa

## unpack_labels function
This function takes a string of semicolon-separated key-value pairs and converts it into a structured dataframe. It splits the input string on semicolons, then further splits each pair on colons to separate keys and values. The result is a two-column dataframe with 'key' and 'value' columns, providing an organized representation of the label data.
```{r}
unpack_labels = function(x){
  # Split the input string by ';'
  kvs = strsplit(x, ';')[[1]]
  
  # Split each key-value pair by ':'
  kvs_split = strsplit(kvs, ':')
  
  # Create a dataframe with columns "key" and "value"
  df = data.frame(
    key = sapply(kvs_split, `[`, 1),
    value = sapply(kvs_split, `[`, 2),
    stringsAsFactors = FALSE
  )
  
  return(df)
}
```

## summarize_comparison function
This function compares two sets of labels (actual and predicted) and generates a summary of their agreement. It processes all unique keys found in both sets, excluding certain taxonomy-related keys, and includes a special 'Taxonomy_all' key. For each key, it calculates the number of actual and predicted values, true positives (TP), false negatives (FN), and false positives (FP). The output is a dataframe summarizing these metrics for each key, enabling detailed analysis of prediction accuracy across different label types.
```{r}
summarize_comparison <- function(actual, predicted) {
  
  # Ensure the key columns are of type character to avoid factor level issues
  actual$key <- as.character(actual$key)
  predicted$key <- as.character(predicted$key)
  
  # Get the unique keys from both actual and predicted, excluding specific keys
  all_keys <- unique(c(actual$key, predicted$key))
  filtered_keys <- setdiff(all_keys, c("Taxonomy_no_rank", "Taxonomy_clade"))
  
  # Add "Taxonomy_all" key to the list of keys
  if (!"Taxonomy_all" %in% filtered_keys) {
    filtered_keys <- c(filtered_keys, "Taxonomy_all")
  }
  
  # Initialize a result dataframe
  result <- data.frame(
    key = filtered_keys,
    N_actual = integer(length(filtered_keys)),
    N_predicted = integer(length(filtered_keys)),
    TP = integer(length(filtered_keys)),
    FN = integer(length(filtered_keys)),
    FP = integer(length(filtered_keys)),
    stringsAsFactors = FALSE
  )
  
  for (key in filtered_keys) {
    if (key == "Taxonomy_all") {
      actual_values <- actual$value[grepl("^Taxonomy_", actual$key)]
      predicted_values <- predicted$value[grepl("^Taxonomy_", predicted$key)]
    } else {
      actual_values <- actual$value[actual$key == key]
      predicted_values <- predicted$value[predicted$key == key]
    }
    
    N_actual <- length(actual_values)
    N_predicted <- length(predicted_values)
    TP <- sum(actual_values %in% predicted_values)
    FN <- sum(!actual_values %in% predicted_values)
    FP <- sum(!predicted_values %in% actual_values)
    
    result[result$key == key, ] <- list(key, N_actual, N_predicted, TP, FN, FP)
  }
  
  return(result)
}
```

## process_dataframe_parallel function
This function performs parallel processing on a dataframe to extract and structure label information. It uses multiple cores to speed up processing of large datasets. For each row, it unpacks the actual and predicted labels, extracts library strategy and platform information, and structures this data into a new dataframe. The result is a processed dataframe with unpacked label information and additional metadata, optimized for further analysis.

```{r}
process_dataframe_parallel <- function(df, num_cores = 16) {
  # Set up parallel processing
  plan(multisession, workers = num_cores)
  
  processed_df <- df %>%
    split(1:nrow(.)) %>%  # Split the dataframe into a list of rows
    future_map_dfr(~ {
      actual = unpack_labels(.x$actual_labels)
      predicted = unpack_labels(.x$predicted_labels)
      library_strategy = actual %>% 
        filter(key == 'LibraryStrategy') %>%
        pull(value)
      platform = actual %>% 
        filter(key == 'Platform') %>%
        pull(value)
      
      tibble(
        sample_id = .x$sample_id,
        query_basepairs = .x$query_basepairs,
        query_mapping = .x$query_mapping,
        actual = list(actual),
        predicted = list(predicted),
        library_strategy = library_strategy,
        platform = platform
      )
    }, .options = furrr_options(seed = TRUE))
  
  # Close the parallel backend
  plan(sequential)
  
  return(processed_df)
}
```

## collate_results function
This function applies the summarize_comparison function to an entire dataframe of predictions. It processes each row, comparing actual and predicted labels and collecting metadata like sample ID, query base pairs, and mapping information. The function then combines all these individual summaries into a single, comprehensive dataframe. This resulting dataframe provides a detailed overview of prediction accuracy across all samples, including various metadata for each comparison.
```{r}
collate_results <- function(predictions_df) {
  predictions_df = predictions_df %>%
    select(sample_id, query_basepairs, query_mapping, actual, predicted, platform, library_strategy)
  # Apply the summarize_comparison function to each row
  results_list <- pmap(predictions_df, function(sample_id, query_basepairs, query_mapping, actual, predicted, platform, library_strategy) {
    result <- summarize_comparison(actual, predicted)
    result$sample_id <- sample_id
    result$query_basepairs <- query_basepairs
    result$query_mapping <- query_mapping
    result$platform = platform
    result$library_strategy = library_strategy
    return(result)
  })
  
  # Combine all results into a single dataframe
  results_df <- bind_rows(results_list)
  return(results_df)
}
```


Read data
```{r}
vk_df = read_csv('all_SRA_taxa/results_varKodes/predictions.csv.zip') %>% process_dataframe_parallel
cgr_df =  read_csv('all_SRA_taxa/results_cgrs/predictions.csv.zip') %>% process_dataframe_parallel

cgr_df
vk_df
```


```{r}
vk_cgr_df = bind_rows(vk_df, cgr_df)
summaries = collate_results(vk_cgr_df) 
summaries
```

Now let's calculate metrics:
```{r}
summaries_with_scores <- summaries %>%
  group_by(key, query_basepairs, query_mapping, platform, library_strategy) %>%
  summarize(
    total_TP = sum(TP),
    total_FN = sum(FN),
    total_FP = sum(FP),
    N = n(),
    .groups = 'drop'
  ) %>%
  mutate(
    microprecision = total_TP / (total_TP + total_FP),
    microrecall = total_TP / (total_TP + total_FN),
    F1 = 2 * (microprecision * microrecall) / (microprecision + microrecall)
  ) %>%
  replace_na(list(microprecision = 0, microrecall = 0, F1 = 0)) %>%
  select(query_basepairs, query_mapping, key, F1, microprecision, microrecall, everything()) %>%
  filter(
      grepl("^[125]0{1,}$", format(query_basepairs, scientific = FALSE, trim = TRUE))
  )

summaries_with_scores
```


# Plots
```{r}
plot_df = summaries_with_scores %>%
  rename(
    precision = microprecision,
    recall = microrecall
  ) %>%
  pivot_longer(
    cols = c(F1, precision, recall),
    names_to = "metric",
    values_to = "metric_value"
  ) %>%
  filter(key %in% c("LibraryStrategy", "Platform", "Taxonomy_all", "Taxonomy_family", "Taxonomy_genus", "Taxonomy_species")) %>%
  mutate(query_mapping = ifelse(query_mapping=='cgr','rfCGR',query_mapping))
```


This graph shows how well the two methods behave to recognize the library strategy:
```{r}
brks = c(500000,
             1000000,
             2000000,
             5000000,
             10000000,
             20000000,
             50000000,
             100000000,
             200000000
             )


plot_df_strat = plot_df %>% filter(key %in% c("LibraryStrategy"))

Ns <- plot_df_strat %>%
  group_by(platform, library_strategy) %>%
  summarize(N = max(N), .groups = "drop") %>%
  mutate(N = paste0("N = ", N))

ggplot(plot_df_strat,
       aes(x=query_basepairs, y=metric_value, color=metric,linetype=query_mapping,group=interaction(metric,query_mapping))) +
  geom_line() +
  facet_grid(platform~library_strategy) +
  labs(title="Accuracy in predicting the library strategy (GBS, RAD or WGS)",
       x="Metric value", 
       y="Base pairs in query images",
       color="Metric",
       linetype="K-mer Mapping") +
  scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = brks)  +
  scale_y_continuous(limits=c(0,1), breaks=c(0,0.2,0.4,0.6,0.8,1)) +
  theme_minimal() +
  theme(text = element_text(size=10),
        axis.text.x = element_text(hjust=1,angle=45)) +
   geom_label(data = Ns, aes(label = N, x = 12000000, y = 0.1),
             hjust = 0.5, vjust = 0.5,
             label.padding = unit(0.2, "lines"),
             label.size = 0.2,
             size=2,
             color = "black",
             fill = "white",
             inherit.aes = FALSE)

safe_ggsave ('images_manuscript/supp_strat_prediction.pdf',width=7,height = 7,useDingbats=F)
```

This graph shows how well the two methods behave to recognize the sequencing platform:
```{r}
ggplot(plot_df %>% filter(key %in% c("Platform")),
       aes(x=query_basepairs, y=metric_value, color=metric,linetype=query_mapping,group=interaction(metric,query_mapping,key))) +
  geom_line() +
  facet_grid(platform~library_strategy) +
  scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = brks)  +
  scale_y_continuous(limits=c(0,1), breaks=c(0,0.2,0.4,0.6,0.8,1)) +
  labs(title="Accuracy in predicting sequencing platform",
       x="Metric value", 
       y="Base pairs in query images",
       color="Metric",
       linetype="K-mer Mapping") +
  theme_minimal() +
  theme(text = element_text(size=10),
        axis.text.x = element_text(hjust=1,angle=45)) +
   geom_label(data = Ns, aes(label = N, x = 12000000, y = 0.1),
             hjust = 0.5, vjust = 0.5,
             label.padding = unit(0.2, "lines"),
             label.size = 0.2,
             size=2,
             color = "black",
             fill = "white",
             inherit.aes = FALSE)

safe_ggsave ('images_manuscript/supp_platform_prediction.pdf',width=7,height = 7,useDingbats=F)
```

This graph shows how well the two methods behave for different taxonomic levels:
```{r}
tax_labels = c("all ranks", "family", "genus", "species")
names(tax_labels) = c("Taxonomy_all", "Taxonomy_family", "Taxonomy_genus", "Taxonomy_species")

plot_df_tax = plot_df %>% 
  filter(key %in% c("Taxonomy_all", "Taxonomy_family", "Taxonomy_genus", "Taxonomy_species")) %>%
  mutate(key = tax_labels[key],
         platform = ifelse(platform=='OXFORD_NANOPORE','NANOPORE',platform))

Ns <- plot_df_tax  %>%
  group_by(platform, library_strategy,key) %>%
  summarize(N = max(N), .groups = "drop") %>%
  mutate(N = paste0("N = ", N))

ggplot(plot_df_tax,
       aes(x=query_basepairs, 
           y=metric_value, color=metric,
           linetype=query_mapping,
           group=interaction(metric,query_mapping,key))) +
  geom_line() +
  facet_grid(key~platform+library_strategy) +   
  scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = brks)  +
  scale_y_continuous(limits=c(0,1), breaks=c(0,0.2,0.4,0.6,0.8,1)) +
  geom_label(data = Ns, aes(label = N, x = 7000000, y = 0.1),
             hjust = 0.5, vjust = 0.5,
             label.padding = unit(0.2, "lines"),
             label.size = 0.2,
             size=2,
             color = "gray30" ,
             fill = "gray96",
             inherit.aes = FALSE) +
  labs(title="Accuracy in predicting taxonomy",
       y="Metric value", 
       x="Base pairs in query images",
       color="Metric",
       linetype="K-mer Mapping") +
  theme_minimal() +
  theme(text = element_text(size=7),
        axis.text.x = element_text(hjust=1,angle=45),
        legend.position = 'bottom')
```
For the manuscript, let's simplify and only show rfCGR:
```{r}
ggplot(plot_df_tax %>% filter(query_mapping=='rfCGR',metric != "F1"),
       aes(x=query_basepairs, 
           y=metric_value, color=metric,
           group=metric)) +
  geom_line() +
  facet_grid(key~platform+library_strategy) +   
  scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),breaks = brks)  +
  scale_y_continuous(limits=c(0,1), breaks=c(0,0.2,0.4,0.6,0.8,1)) +
  geom_label(data = Ns, aes(label = N, x = 7000000, y = 0.1),
             hjust = 0.5, vjust = 0.5,
             label.padding = unit(0.2, "lines"),
             label.size = 0.2,
             size=2,
             color = "gray30" ,
             fill = "gray96",
             inherit.aes = FALSE) +
  labs(title="Accuracy in predicting taxonomy",
       y="Metric value", 
       x="Base pairs in query images",
       color="Metric",
       linetype="K-mer Mapping") +
  theme_minimal() +
  theme(text = element_text(size=7),
        axis.text.x = element_text(hjust=1,angle=45),
        legend.position = 'bottom')

safe_ggsave ('images_manuscript/fig_5_taxonomy_prediction.pdf',width=7,height = 5,useDingbats=F)
```
Let's now try to understand the relationship between number of samples available for a label and its accuracy. For each label, we will summarize the N in training set, precision, recall and F1 score in the validation set. Then we will plot the relationship between number of training samples and validation metrics.

```{r}
summarize_comparison_with_value <- function(actual, predicted) {
  
  actual <- actual %>% mutate(k_v = paste(key, value, sep = ":"))
  predicted <- predicted %>% mutate( k_v = paste(key, value, sep = ":"))
  
  # Get the unique keys from both actual and predicted, excluding specific keys
  all_kv <- unique(c(actual$k_v, predicted$k_v))
  
  
  # Initialize a result dataframe
  result <- data.frame(
    k_v = all_kv,
    N_actual = integer(length(all_kv)),
    N_predicted = integer(length(all_kv)),
    TP = integer(length(all_kv)),
    FN = integer(length(all_kv)),
    FP = integer(length(all_kv)),
    stringsAsFactors = FALSE
  )
  
  for (k_v in all_kv) {
    actual_values <- actual$value[actual$k_v == k_v]
    predicted_values <- predicted$value[predicted$k_v == k_v]
    
    N_actual <- length(actual_values)
    N_predicted <- length(predicted_values)
    TP <- sum(actual_values %in% predicted_values)
    FN <- sum(!actual_values %in% predicted_values)
    FP <- sum(!predicted_values %in% actual_values)
    
    result[result$k_v == k_v, ] <- list(k_v, N_actual, N_predicted, TP, FN, FP)
  }
  
  return(result)
}
```

```{r}
collate_results_with_value <- function(predictions_df) {
  predictions_df = predictions_df %>%
    select(sample_id, query_basepairs, query_mapping, actual, predicted, platform, library_strategy)
  # Apply the summarize_comparison function to each row
  results_list <- pmap(predictions_df, function(sample_id, query_basepairs, query_mapping, actual, predicted, platform, library_strategy) {
    result <- summarize_comparison_with_value(actual, predicted)
    result$sample_id <- sample_id
    result$query_basepairs <- query_basepairs
    result$query_mapping <- query_mapping
    result$platform = platform
    result$library_strategy = library_strategy
    return(result)
  })
  
  # Combine all results into a single dataframe
  results_df <- bind_rows(results_list)
  return(results_df)
}
```

```{r}
summaries_kv = collate_results_with_value(vk_cgr_df)
summaries_kv
```
```{r}
metrics_by_label = summaries_kv %>%
  select(-sample_id,-query_basepairs) %>%
  group_by(k_v) %>%
  summarise(across(where(is.numeric), sum)) %>%
  mutate(
    microprecision = TP / (TP + FP),
    microrecall = TP / (TP + FN),
    F1 = 2 * (microprecision * microrecall) / (microprecision + microrecall)
  ) %>%
  replace_na(list(microprecision = 0, microrecall = 0, F1 = 0))
  
metrics_by_label
```

Now we only need to count the occurrences of each label in the training set
```{r}
metrics_by_label = read_csv('all_SRA_taxa/labels_ML_training.csv.gz') %>%
  filter(!sample %in% vk_cgr_df$sample_id) %>%
  pull(labels) %>%
  str_split(';') %>%
  unlist %>%
  table %>%
  as_tibble(column_name='k_v',n="N_training") %>%
  rename(k_v = ".") %>%
  right_join(metrics_by_label) %>%
  pivot_longer(microprecision:F1,names_to = 'metric',values_to = 'value') %>%
  arrange(N_training) 

metrics_by_label
```
```{r}
metrics_summary <- metrics_by_label %>%
  filter(metric !='F1') %>%
  # Create log-scaled bins
  mutate(bin = cut(log10(N_training), breaks = 30)) %>%
  group_by(bin, metric) %>%
  summarise(
    median = median(value),
    q25 = quantile(value, 0.25),
    q75 = quantile(value, 0.75),
    # Get middle of the bin for plotting
    x = median(N_training),
    N=n()
  )
metrics_summary 

ggplot() +
  geom_bin2d(data = metrics_by_label %>% filter(metric !='F1'), aes(x = N_training, y = value)) +
  #geom_ribbon(data = metrics_summary,
  #            aes(x = x, ymin = q25, ymax = q75),
  #           alpha = 0.2,
  #            fill = "blue") +
  geom_line(data = metrics_summary,
            aes(x = x, y = median),
            color = "orange",
            linewidth = 1) +
    #geom_point(data = metrics_by_label %>% filter(metric !='F1'), 
    #          aes(x = N_training, y = value),
    #          alpha = 0.1) +
  scale_x_log10() +
  scale_y_continuous(breaks=seq(0,1,0.1)) +
  scale_fill_viridis_c(trans="log",name="Label counts",breaks=c(1,3,10,30,100,300,1000)) +
  facet_wrap(~metric, labeller = labeller(metric=c('microprecision'='Precision','microrecall'='Recall'))) +
  theme_minimal() +
  labs(
    x = "Number of Training Examples (log scale)",
    y = "Value",
    title = "Validation Metrics by Training Set Size"
  )

safe_ggsave ('images_manuscript/fig_X_n_train.pdf',width=7,height = 2.5,useDingbats=F)
```


Let's now get some numbers for publication. What is the average precision at species level?
```{r}
plot_df %>%
  filter(key=='Taxonomy_species',
         metric %in% c('precision','recall'),
         query_mapping=='varKode') %>%
  group_by(metric,platform) %>%
  summarise(mean_value=mean(metric_value))
  
```

Genus level
```{r}
plot_df %>%
  filter(key=='Taxonomy_genus',
         metric %in% c('precision','recall'),
         query_mapping=='varKode') %>%
  group_by(metric,platform) %>%
  summarise(mean_value=mean(metric_value))
  
```

Family level
```{r}
plot_df %>%
  filter(key=='Taxonomy_family',
         metric %in% c('precision','recall'),
         query_mapping=='varKode') %>%
  group_by(metric,platform) %>%
  summarise(mean_value=mean(metric_value))
```

All taxonomy
```{r}
plot_df %>%
  filter(key=='Taxonomy_all',
         metric %in% c('precision','recall'),
         query_mapping=='varKode') %>%
  group_by(metric,platform) %>%
  summarise(mean_value=mean(metric_value))
```




# Generating numbers for publication

Here we just query our results to get a few figures that we report in the paper.

Total number of samples used in cross-validation:
```{r}
dim(samp_labels)
```

Number of Stigmaphyllon samples with each kind of error for varkoder:
```{r}
summary_species
```

Number of Stigmaphyllon samples with each kind of error for skmer:
```{r}
skmer_summary_species
```
Traditional barcode accuracy for species:
```{r}
barcode_summary_species %>% arrange(query_bp,marker)
```
Concatenated barcode accuract for species:
```{r}
concat_summary_species
```

varKoder accuracy for genera:
```{r}
summary_genus
```
varKoder accuracy for family:
```{r}
summary_family
```

Skmer accuracy for genera:
```{r}
skmer_summary_genus
```

Skmer accuracy for family:
```{r}
skmer_summary_family
```

Number of samples available for each genus and data amount
```{r}
results %>%
  mutate(genus = str_extract(actual_labels,"(?<=genus:)[^;]+")) %>%
  group_by(query_bp) %>%
  summarize(N=n()) %>%
  complete()
```

Plot number of samples for supplementary material.

```{r}
n_samples_genera = results %>%
  mutate(taxon = str_extract(actual_labels,"(?<=genus:)[^;]+")) %>%
  group_by(taxon, query_bp) %>%
  summarize(N=n()) %>%
  ungroup() %>%
  complete(taxon, query_bp, fill = list(N=0)) %>%
  mutate(taxon = fct_reorder(taxon, N))
n_samples_genera 

n_samples_species = results %>%
  mutate(taxon = str_extract(actual_labels,"(?<=species:)[^;]+")) %>%
  filter(!is.na(taxon)) %>%
  group_by(taxon, query_bp) %>%
  summarize(N=n()) %>%
  ungroup() %>%
  complete(taxon, query_bp, fill = list(N=0))  %>%
  mutate(taxon = fct_reorder(taxon, N))
n_samples_species 
```

For SRA eukaryotes, we have to count both validation and training samples, since we did not do cross-validation. Let's use image names to get the information and then the results table to figure out which ones were in the validation set.
```{r}
all_files = c(list.files('all_SRA_eukaryote_families/varkoder_images_SRA/',pattern='*.png',recursive = T),
              list.files('all_SRA_eukaryote_familiesvarkoder_query_images/',pattern='*.png',recursive = T))

n_samples_SRA = data.frame(filename=all_files) %>%
  mutate(
    sample_id = str_extract(filename, "^(.+)(?=@)"),  # Capture everything up to the "@" symbol but exclude the symbol itself
    query_bp = str_extract(filename, "(?<=@)([0-9]+)K") # multiply by 1000 to convert K to the actual number
  ) %>% 
  left_join(read_csv('all_SRA_eukaryote_families/runs_to_download_data.csv') %>% 
              select(sample_id=Run,Kingdom,taxon=FamilyID)) %>%
  mutate_at(vars(taxon),as.character) %>%
  mutate(validation_set = sample_id %in% varKoder_SRA_results$sample_id) %>%
  group_by(taxon, query_bp,validation_set) %>%
  summarize(N=n()) %>%
  ungroup() %>%
  mutate(taxon = fct_reorder(taxon, N))

n_samples_SRA
  

  ((list.files('all_SRA_eukaryote_familiesvarkoder_images_SRA/',pattern='*.png',recursive = T) %>%
      str_extract("^(.+)(?=@)"))%in%
varKoder_SRA_results$sample_id) %>% summary
```



```{r}
plot_Nsamples_area = function(df, title){
  df = df #%>% 
   # mutate(query_bp = parse_number(query_bp) *1000)
  
  n_levels <- length(unique(df$taxon))
  viridis_colors <- viridis::turbo(n_levels)
  
  half_n <- ceiling(n_levels / 2)
  reordered_colors <- c(rbind(viridis_colors[1:half_n], viridis_colors[(half_n + 1):n_levels]))


  
  
  ggplot(df, aes(x=query_bp,y=N,fill=taxon, color = taxon, group = taxon)) +
    geom_area(position= position_stack()) +
    #geom_line(position='stack') +
    scale_fill_manual(values = reordered_colors, 
                      aesthetics = c('colour','fill'),
                      guide = 'none') +
    scale_x_log10(labels = scales::label_number(scale_cut = scales::cut_si('bp')),
                  breaks = unique(n_samples_genera$query_bp),
                  limits = range(unique(n_samples_genera$query_bp))) +
    scale_y_continuous(n.breaks = 10, minor_breaks = waiver()) +
    ggtitle(title) +
    ylab('Number of samples') +
    xlab('Base pairs in query images') +
    theme_few() +
    theme(axis.text.x = element_text(hjust=1,angle=45),
          panel.background = element_rect(fill = NA),
            panel.grid.major.y = element_line(colour = gray(0.5)),
            panel.grid.minor.y = element_line(colour = gray(0.6),linetype = 2),
            panel.ontop = TRUE)
}
```

```{r}

N_species = plot_Nsamples_area(n_samples_species, title = expression(italic('Stigmaphyllon')~'species')) + theme(axis.title.x = element_blank(),text = element_text(size=8))
N_genera = plot_Nsamples_area(n_samples_genera, title = 'Malpighiales genera') + theme(axis.title.x = element_blank(),text = element_text(size=8))

p = plot_grid(N_species, N_genera, nrow = 1)

# Add common plot title with white background
common_title = ggdraw() + draw_label("Number of samples available for different data amounts", fontface = 'bold', x = 0.5, hjust = 0.5) + theme(plot.background = element_rect(fill = "white", color = "white"), plot.margin = unit(c(0, 0, 0, 0), "null"))
p = plot_grid(common_title, p, ncol = 1, rel_heights = c(0.1, 1))

# Add common X-axis title with white background
x_axis_title = ggdraw() + draw_label("Post-cleaning base pairs available", x = 0.5, hjust = 0.5, vjust = 1) + theme(plot.background = element_rect(fill = "white", color = "white"), plot.margin = unit(c(-1, 0, 0, 0), "lines"))
p = plot_grid(p, x_axis_title, ncol = 1, rel_heights = c(1, 0.1))


print(p)

safe_ggsave ('images_manuscript/supp_fig_n_samples.pdf', width=8,height = 4)
safe_ggsave ('images_manuscript/supp_fig_n_samples.png', width=8,height = 4,dpi = 1200)

```

Total number of SRA eukaryote family samples. Validation:
```{r}
read_csv('all_SRA_eukaryote_families/varkoder_trained_model_ML/input_data.csv')[-1] %>%
  group_by(is_valid) %>%
  summarise(N = n())
```

For SRA all taxa, let's summarize the number of samples for each label. Let's start by parsing the data. We will start with train_valid_sets.csv but then filter to the samples actually used. A few might have failed to produce varKodes.

```{r}
plan(multisession, workers = 10)


all_SRA_samples = read_csv("all_SRA_taxa/train_valid_sets.csv.gz") %>%
  split(1:nrow(.)) %>%  # Split the dataframe into a list of rows
  future_map_dfr( ~ {
    actual = unpack_labels(.x$labels)
    library_strategy = actual %>%
      filter(key == 'LibraryStrategy') %>%
      pull(value)
    platform = actual %>%
      filter(key == 'Platform') %>%
      pull(value)
    
    tibble(
      sample_id = .x$Run,
      labels = list(actual),
      library_strategy = library_strategy,
      platform = platform,
      is_valid = .x$is_valid
    )
  }, .options = furrr_options(seed = TRUE)
  )

plan(sequential)

actual_tr = read_csv("all_SRA_taxa/varkodes_ViT_ML/input_data.csv")  %>% filter(is_valid==FALSE) %>% pull(sample) %>% unique
actual_vd = read_csv("all_SRA_taxa/results_varKodes/predictions.csv.zip") %>% pull(sample_id) %>% unique

all_SRA_samples = all_SRA_samples%>% filter(sample_id %in% c(actual_tr,actual_vd))
all_SRA_samples

```

Now let's count the number of samples for each label
```{r}
N_summary = all_SRA_samples %>%
  unnest(labels) %>%
  rename(label_key = key, label_value = value) %>%
  group_by(is_valid,library_strategy,platform,label_key,label_value) %>%
  summarize(N_samples = n(), .groups = "drop") %>%
  filter(label_key %in% c('Taxonomy_family','Taxonomy_species'))

N_summary
```

Now, for each combination of library strategy, platform and whether sample is validation, we will summarize the range, mean and median number of samples per label.

```{r}
N_per_label_key = N_summary %>%
  group_by(is_valid, platform, library_strategy, label_key) %>%
  summarise(
    n_labels = n(),
    min = min(N_samples, na.rm = TRUE),
    q1 = quantile(N_samples, 0.25, na.rm = TRUE),
    median = median(N_samples, na.rm = TRUE),
    mean = mean(N_samples, na.rm = TRUE),
    q3 = quantile(N_samples, 0.75, na.rm = TRUE),
    max = max(N_samples, na.rm = TRUE)
  ) %>%
  ungroup()

N_per_label_key

dir.create('tables_manuscript',showWarnings = F)
write_csv(N_per_label_key, 'tables_manuscript/summary_samples_all_SRA.csv')
```
Let's now count the total number of unique taxonomy labels:
```{r}
N_summary %>% 
  filter(str_detect(label_key,'^Taxonomy')) %>%
  pull(label_value) %>%
  unique %>%
  length()
```


And the number of unique accessions:
```{r}
all_SRA_samples$sample_id %>% unique %>% length()
```



## Precision and recall
### all SRA

Pooled across sequencing methods for families and all
```{r}
summaries_with_scores %>% filter(key %in% c('Taxonomy_family','Taxonomy_all')) %>% group_by(key) %>%
  summarise(min_pr=min(microprecision),
            max_pr=max(microprecision),
            min_rec=min(microrecall),
            max_rec=max(microrecall))
```
Discriminating sequencing methods for genera and species
```{r}
summaries_with_scores %>% 
  filter(key %in% c('Taxonomy_genus','Taxonomy_species'),
         query_basepairs == 10000000) %>% 
  arrange(key,desc(microprecision))
```

Now let's compare averages across mapping for species level.
```{r}
summaries_with_scores %>% 
  filter(key %in% c('Taxonomy_species')) %>% 
  group_by(query_mapping) %>%
  summarise(mean(microprecision), mean(microrecall))
```



### Other datasets
Calculate micro-averaged precision and recall.

```{r}

calculate_precision_recall = function(results, taxonomic_level=NULL) {
  # Function to filter labels by taxonomic level
  filter_labels <- function(labels_list, level) {
    if (is.null(level)) {
      return(labels_list)
    } else {
      return(grep(paste0("^", level, ":"), labels_list, value = TRUE))
    }
  }

  # Filter rows and labels for a given taxonomic level
  filter_rows_and_labels <- function(results, level) {
    if (is.null(level)) {
      return(results)
    } else {
      # Keep only rows where the level is found in query_labels
      filtered_results <- results[sapply(results$query_labels, function(x) {
        any(grepl(paste0("^", level, ":"), x))
      }), ]

      # Filter labels in both query_labels and predicted_list
      filtered_results$query_labels <- lapply(filtered_results$query_labels, filter_labels, level)
      filtered_results$predicted_list <- lapply(filtered_results$predicted_list, filter_labels, level)

      return(filtered_results)
    }
  }

  # Apply filtering
  filtered_results <- filter_rows_and_labels(results, taxonomic_level)

  # Initialize counters for true positives, false positives, and false negatives
  total_true_positives <- 0
  total_false_positives <- 0
  total_false_negatives <- 0

  # Process each row in the filtered results
  for (i in seq_len(nrow(filtered_results))) {
    query_labels <- filtered_results$query_labels[[i]]
    predicted_labels <- filtered_results$predicted_list[[i]]

    true_positives <- sum(predicted_labels %in% query_labels)
    false_positives <- sum(!predicted_labels %in% query_labels & !is.na(predicted_labels) & predicted_labels != "")
    false_negatives <- sum(!query_labels %in% predicted_labels & !is.na(query_labels) & query_labels != "")

    # Update aggregate counts
    total_true_positives <- total_true_positives + true_positives
    total_false_positives <- total_false_positives + false_positives
    total_false_negatives <- total_false_negatives + false_negatives
  }

  # Calculate micro-averaged precision and recall
  micro_precision <- ifelse((total_true_positives + total_false_positives) > 0, 
                            total_true_positives / (total_true_positives + total_false_positives), 
                            NA_real_)
  micro_recall <- ifelse((total_true_positives + total_false_negatives) > 0, 
                         total_true_positives / (total_true_positives + total_false_negatives), 
                         NA_real_)

  return(tibble(taxonomic_level = taxonomic_level, micro_precision = micro_precision, micro_recall = micro_recall))
}

```


#### Malpighiales
Precision and recall for species:

```{r}
filter(results,str_detect(actual_labels,'species')) %>%
         split(.$query_bp) %>%
         map_dfr(~calculate_precision_recall(.x,'species'),.id='query_bp')
```

Precision and recall for genera:

```{r}
filter(results,str_detect(actual_labels,'genus')) %>%
         split(.$query_bp) %>%
         map_dfr(~calculate_precision_recall(.x,'genus'),.id='query_bp')
```

Precision and recall for families:

```{r}
filter(results,str_detect(actual_labels,'family')) %>%
         split(.$query_bp) %>%
         map_dfr(~calculate_precision_recall(.x,'family'),.id='query_bp')
```

#### SRA eukaryotes
Precision and recall for SRA eukaryote families, rfCGR representation:
```{r}
pr_rc_euk_SRA = varKoder_SRA_results %>%
  split(.$query_bp) %>%
         map_dfr(~calculate_precision_recall(.x),.id='query_bp') %>%
  mutate(query_bp = 1000*(str_remove(query_bp,'K') %>% as.numeric))
pr_rc_euk_SRA
```

Precision and recall for SRA eukaryote families, varKode representation:
```{r}
pr_rc_euk_SRA_vk = varKoder_SRA_results_vk %>%
  split(.$query_bp) %>%
         map_dfr(~calculate_precision_recall(.x),.id='query_bp') %>%
  mutate(query_bp = 1000*as.integer(query_bp))
pr_rc_euk_SRA_vk
```
Let's join both tables:
```{r}
full_join(pr_rc_euk_SRA,pr_rc_euk_SRA_vk,by="query_bp",suffix = c('.varKode','.rfCGR'))
```


Precision and recall for other taxa, varKode representation:
```{r}
other_results %>%
  filter(in_training_model == 'yes') %>%
  split(.$dataset) %>%
  map_dfr(~calculate_precision_recall(.x),.id='dataset')
```

Precision and recall for other taxa, CGR representation:
```{r}
other_results_CGR %>%
  filter(in_training_model == 'yes') %>%
  split(.$dataset) %>%
  map_dfr(~calculate_precision_recall(.x),.id='dataset')
```

Numbers correct and icorrect, CGR:
```{r}
summary_others_CGR %>% group_by(dataset,result,taxon_in_training) %>% summarise(N=sum(N),p=mean(p)) 
```


Precision and recall for conventional barcodes at species level
```{r}
results_barcodes %>%
  group_by(marker,query_bp) %>%
  nest() %>%
  mutate(precision_recall = purrr::map(data, calculate_precision_recall,'species')) %>%
  select(-data) %>%
  unnest(precision_recall)
```
Precision and recall for concatenated conventional barcodes at species level
```{r}
results_concat_barcodes %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x),.id='query_bp','species')
```

Precision/recall for skmer at species level. Precision and recall are not always the same because in some cases skmer predicted the wrong genus, and, therefore, there was no species prediction.

```{r}
skmer_results_df %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x,'species'),.id='query_bp')
```


Precision and recall for conventional barcodes at genus level
```{r}
results_barcodes %>%
  group_by(marker,query_bp) %>%
  nest() %>%
  mutate(precision_recall = purrr::map(data, calculate_precision_recall,'genus')) %>%
  select(-data) %>%
  unnest(precision_recall)
```
Precision and recall for concatenated conventional barcodes at genus level
```{r}
results_concat_barcodes %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x),.id='query_bp','genus')
```

Precision/recall for skmer at genus level:

```{r}
skmer_results_df %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x,'genus'),.id='query_bp')
```



Precision and recall for conventional barcodes at family level
```{r}
results_barcodes %>%
  group_by(marker,query_bp) %>%
  nest() %>%
  mutate(precision_recall = purrr::map(data, calculate_precision_recall,'family')) %>%
  select(-data) %>%
  unnest(precision_recall)
```
Precision and recall for concatenated conventional barcodes at family level
```{r}
results_concat_barcodes %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x),.id='query_bp','family')
```

Precision/recall for skmer at family level:

```{r}
skmer_results_df %>%
  split(.$query_bp) %>%
  map_dfr(~calculate_precision_recall(.x,'family'),.id='query_bp')
```

# Aditional numbers for second round of reviews:

##Table with number of training and validation samples for each label in the all-SRA dataset

Let's start by the training set:
```{r}
SRA_train_label_counts = read_csv('all_SRA_taxa/varkodes_ViT_ML/input_data.csv') %>%
  filter(is_valid == FALSE) %>%
  # Get one row per sample
  group_by(sample) %>%
  slice_head(n=1) %>%
  # Split the labels string into separate rows
  select(sample, labels) %>%
  separate_rows(labels, sep = ";") %>%
  # Count occurrences of each label
  group_by(labels) %>%
  summarise(N_samples = n()) %>%
  # Sort by frequency
  arrange(desc(N_samples))
SRA_train_label_counts
```
Now let's do the same for the validation set:
```{r}
SRA_valid_label_counts = read_csv('all_SRA_taxa/results_cgrs/predictions.csv.zip') %>%
  # Get one row per sample
  group_by(sample_id) %>%
  slice_head(n=1) %>%
  # Split the labels string into separate rows
  select(sample = sample_id, labels = actual_labels) %>%
  separate_rows(labels, sep = ";") %>%
  # Count occurrences of each label
  group_by(labels) %>%
  summarise(N_samples = n()) %>%
  # Sort by frequency
  arrange(desc(N_samples))

SRA_valid_label_counts 
```
And now let's join both:
```{r}
all_SRA_label_counts = SRA_train_label_counts %>% 
  left_join(SRA_valid_label_counts,by = "labels",suffix = c("_train",'_valid')) %>%
  replace(is.na(.), 0) 
all_SRA_label_counts

write_csv(all_SRA_label_counts,'tables_manuscript/label_counts_all_SRA.csv')

```


Now let's look at the distribution of data amounts in the training set:

```{r}
# Define the possible values
break_points <- c(-Inf, 5e5, 1e6, 2e6, 5e6, 1e7, 2e7, Inf)  
target_values <- c(0, 5e5, 1e6, 2e6, 5e6, 1e7, 2e7)    

max_query_bp_raw = read_csv('all_SRA_taxa/varkodes_ViT_ML/input_data.csv') %>%
    # Get one row per sample
    group_by(sample) %>%
    summarise(max_query_bp = max(bp)) %>%
    # Round down to previous target value
    mutate(max_query_bp = target_values[findInterval(max_query_bp, break_points, rightmost.closed=TRUE)])

summary_data_distribution_SRA = max_query_bp_raw %>%
 group_by(max_query_bp) %>%
 summarise(N=n()) %>%
  ungroup() %>%
  mutate(p = N/sum(N) * 100) %>%
  arrange(desc(max_query_bp)) %>%
  mutate(p = cumsum(p))

summary_data_distribution_SRA 
```

## Table with number of training and validation samples for each label in the eukarya dataset. 

Let's start by the training set:
```{r}
eukarya_train_label_counts = read_csv('all_SRA_eukaryote_families/varkoder_trained_model_ML/input_data.csv') %>%
  filter(is_valid == FALSE) %>%
  # Get one row per sample
  group_by(sample) %>%
  slice_head(n=1) %>%
  # Split the labels string into separate rows
  select(sample, labels) %>%
  separate_rows(labels, sep = ";") %>%
  # Count occurrences of each label
  group_by(labels) %>%
  summarise(N_samples = n()) %>%
  # Sort by frequency
  arrange(desc(N_samples))
eukarya_train_label_counts
```
Now let's do the same for the validation set:
```{r}
eukarya_valid_label_counts = read_csv('all_SRA_eukaryote_families/varkoder_query_results/predictions.csv') %>%
  bind_rows(read_csv('all_SRA_eukaryote_families/varkoder_query_notincluded_results/predictions.csv')) %>%
  # Get one row per sample
  group_by(sample_id) %>%
  slice_head(n=1) %>%
  # Split the labels string into separate rows
  select(sample = sample_id, labels = actual_labels) %>%
  separate_rows(labels, sep = ";") %>%
  # Count occurrences of each label
  group_by(labels) %>%
  summarise(N_samples = n()) %>%
  # Sort by frequency
  arrange(desc(N_samples))

eukarya_valid_label_counts 
```
And now let's join both:
```{r}
eukarya_label_counts = eukarya_train_label_counts %>% 
  full_join(eukarya_valid_label_counts,by = "labels",suffix = c("_train",'_valid')) %>%
  replace(is.na(.), 0) %>%
  rename(`NCBI taxonomy ID`=labels)
eukarya_label_counts

write_csv(eukarya_label_counts,'tables_manuscript/label_counts_eukarya.csv')

```


Now let's look at the distribution of data amounts in the training set:

```{r}
# Define the possible values
break_points <- c(-Inf, 5e5, 1e6, 2e6, 5e6, 1e7, 2e7, Inf)  
target_values <- c(0, 5e5, 1e6, 2e6, 5e6, 1e7, 2e7)    

eukarya_max_query_bp_raw = read_csv('all_SRA_eukaryote_families/varkoder_trained_model_ML/input_data.csv') %>%
    # Get one row per sample
    group_by(sample) %>%
    summarise(max_query_bp = max(bp)) %>%
    # Round down to previous target value
    mutate(max_query_bp = target_values[findInterval(max_query_bp, break_points, rightmost.closed=TRUE)])

eukarya_summary_data_distribution = eukarya_max_query_bp_raw %>%
 group_by(max_query_bp) %>%
 summarise(N=n()) %>%
  ungroup() %>%
  mutate(p = N/sum(N) * 100) %>%
  rename(`Amount of data (basepairs)`=max_query_bp,
         `Number of samples`=N,
         `Proportion of samples`=p)

eukarya_summary_data_distribution

```

## Summary table for all methods, all levels, etc for Malpighiales dataset

We will now prepare a big summary table including skmer, blast and phylogeny results. All CNN results already exist from the CGR comparison, so we will manually prepare the final table.

```{r}
# Split by marker and calculate metrics for each taxonomic level
conventional_barcode_prec_recall = results_barcodes %>%
    ungroup() %>%
    group_by(marker) %>%
    group_split() %>%
    map_dfr(~{
        marker_val <- .x$marker[1]
        bind_rows(
            calculate_precision_recall(.x, taxonomic_level = 'family') %>% 
                mutate(taxonomic_level = 'family', marker = marker_val),
            calculate_precision_recall(.x, taxonomic_level = 'genus') %>% 
                mutate(taxonomic_level = 'genus', marker = marker_val),
            calculate_precision_recall(.x, taxonomic_level = 'species') %>% 
                mutate(taxonomic_level = 'species', marker = marker_val)
        )
    }) %>%
  arrange(marker, taxonomic_level) %>%
  transmute(method=paste("BLAST",marker,sep=", "),
            taxonomic_level = taxonomic_level,
            precision=micro_precision,
            recall=micro_recall)

phylo_prec_recall = bind_rows(
  calculate_precision_recall(results_concat_barcodes, taxonomic_level = 'family'),
  calculate_precision_recall(results_concat_barcodes, taxonomic_level = 'genus'),
  calculate_precision_recall(results_concat_barcodes, taxonomic_level = 'species')
) %>%
  transmute(method="Concatenated phylogeny",
            taxonomic_level = taxonomic_level,
            precision=micro_precision,
            recall=micro_recall)

skmer_prec_recall = bind_rows(
  calculate_precision_recall(skmer_results_df, taxonomic_level = 'family'),
  calculate_precision_recall(skmer_results_df, taxonomic_level = 'genus'),
  calculate_precision_recall(skmer_results_df, taxonomic_level = 'species')
) %>%
  transmute(method="Skmer",
            taxonomic_level = taxonomic_level,
            precision=micro_precision,
            recall=micro_recall)

prec_recall_all = rbind(conventional_barcode_prec_recall, phylo_prec_recall, skmer_prec_recall)

prec_recall_all

write_csv(prec_recall_all, 'tables_manuscript/precision_recall_Malpighiales.csv')
```



## Summary table comparing fCGR to varKodes
```{r}

diverse_datasets_prec_rec = other_results %>%
  group_by(dataset) %>%
  group_split() %>%
  map_dfr(~{
    dataset_val <- .x$dataset[1]
    calculate_precision_recall(.x) %>% 
      mutate(dataset = dataset_val)
  }) %>%
  transmute(
    dataset = paste("Diverse species-level", dataset, sep=", "),
    representation = "varKode",
    precision = micro_precision,
    recall = micro_recall
  )

diverse_datasets_prec_rec_cgr = other_results %>%
  group_by(dataset) %>%
  group_split() %>%
  map_dfr(~{
    dataset_val <- .x$dataset[1]
    calculate_precision_recall(.x) %>% 
      mutate(dataset = dataset_val)
  }) %>%
  transmute(
    dataset = paste("Diverse species-level", dataset, sep=", "),
    representation = "rfCGR",
    precision = micro_precision,
    recall = micro_recall
  )

eukarya_prec_rec =  varKoder_SRA_results_vk %>%
    calculate_precision_recall() %>%
  transmute(dataset="Eukaryote families",
            representation="varKode",
            precision=micro_precision,
            recall=micro_recall)

eukarya_prec_rec_CGR =varKoder_SRA_results %>%
    calculate_precision_recall() %>%
  transmute(dataset="Eukaryote families",
            representation="rfCGR",
            precision=micro_precision,
            recall=micro_recall)

vk_vs_rfCGR = rbind(diverse_datasets_prec_rec, 
      diverse_datasets_prec_rec_cgr,
      eukarya_prec_rec,
      eukarya_prec_rec_CGR)

vk_vs_rfCGR

write_csv(vk_vs_rfCGR, "tables_manuscript/vk_vs_rfCGR.csv")

```

Now let's do the same for the all-SRA dataset:
```{r}
prec_recall_allSRA = summaries %>%
  filter(str_starts(key, "Taxonomy_")) %>%
  group_by(query_mapping, platform, library_strategy) %>%
  summarize(
    total_TP = sum(TP),
    total_FN = sum(FN),
    total_FP = sum(FP),
    N = n(),
    .groups = 'drop'
  ) %>%
  mutate(
    microprecision = total_TP / (total_TP + total_FP),
    microrecall = total_TP / (total_TP + total_FN),
    F1 = 2 * (microprecision * microrecall) / (microprecision + microrecall)
  ) %>%
  select(query_mapping, F1, microprecision, microrecall, everything())

prec_recall_allSRA
write_csv(prec_recall_allSRA, "tables_manuscript/prec_recall_allSRA.csv")
```




